{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.188796Z",
     "iopub.status.busy": "2023-05-01T14:41:58.187587Z",
     "iopub.status.idle": "2023-05-01T14:41:58.200553Z",
     "shell.execute_reply": "2023-05-01T14:41:58.199129Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.188748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.optim import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lion_pytorch import Lion\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import font_manager, rc\n",
    "from IPython import display\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc\n",
    "import random\n",
    "import urllib.request\n",
    "\n",
    "print(\"Version of Torch : {0}\".format(torch.__version__))\n",
    "print(\"Version of TorchVision : {0}\".format(torchvision.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.20245Z",
     "iopub.status.busy": "2023-05-01T14:41:58.202002Z",
     "iopub.status.idle": "2023-05-01T14:41:58.428917Z",
     "shell.execute_reply": "2023-05-01T14:41:58.427638Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.202403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.448169Z",
     "iopub.status.busy": "2023-05-01T14:41:58.447828Z",
     "iopub.status.idle": "2023-05-01T14:41:58.45744Z",
     "shell.execute_reply": "2023-05-01T14:41:58.456167Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.448138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Device\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "print(\"Device : {0}\".format(\"GPU\" if USE_CUDA else \"CPU\"))\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "# Train\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 20\n",
    "START_EPOCH = 1\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "MAX_LEN = 10\n",
    "DATASET_PATH = [\n",
    "#    \"/kaggle/input/large-captcha-dataset/Large_Captcha_Dataset\",\n",
    "#    \"/kaggle/input/captcha-dataset\",\n",
    "#    \"/kaggle/input/comprasnet-captchas/comprasnet_imagensacerto\",\n",
    "#    \"/kaggle/input/captcha-images\",\n",
    "#    \"/kaggle/input/captcha-version-2-images/\",\n",
    "#    \"/kaggle/input/new-captcha1000\",\n",
    "    \"/kaggle/input/new-captcha-30000\"\n",
    "]\n",
    "\n",
    "BAN_DATA = [\n",
    "]\n",
    "\n",
    "RANDOM_SEED = 2004\n",
    "\n",
    "USE_CHECKPOINT = True\n",
    "CHECKPOINT_PATH = \"/kaggle/input/captcha/pytorch/default/2/Checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.459829Z",
     "iopub.status.busy": "2023-05-01T14:41:58.459177Z",
     "iopub.status.idle": "2023-05-01T14:41:58.474309Z",
     "shell.execute_reply": "2023-05-01T14:41:58.473391Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.459794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_seed():\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    print('Random Seed : {0}'.format(RANDOM_SEED))\n",
    "    \n",
    "random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.476783Z",
     "iopub.status.busy": "2023-05-01T14:41:58.475735Z",
     "iopub.status.idle": "2023-05-01T14:41:58.487723Z",
     "shell.execute_reply": "2023-05-01T14:41:58.486838Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.476746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if USE_CHECKPOINT:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    START_EPOCH = checkpoint[\"epoch\"]+1\n",
    "    print(\"Loading Checkpoint [START_EPOCH : {0}]\".format(START_EPOCH))\n",
    "else :\n",
    "    START_EPOCH = 1\n",
    "    print(\"Training New Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.489332Z",
     "iopub.status.busy": "2023-05-01T14:41:58.489006Z",
     "iopub.status.idle": "2023-05-01T14:41:58.501398Z",
     "shell.execute_reply": "2023-05-01T14:41:58.500171Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.489302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "special_char_list = [\"<pad>\"] # [\"<unk>\", \"<pad>\"]\n",
    "num_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "upper_alphabet_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "lower_alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "string_list = special_char_list + num_list + upper_alphabet_list + lower_alphabet_list\n",
    "CHAR_NUM = len(string_list)\n",
    "\n",
    "token_dictionary = {i : string_list[i] for i in range(len(string_list))}\n",
    "reversed_token_dictionary = {v: k for k, v in token_dictionary.items()}\n",
    "\n",
    "print(CHAR_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.503527Z",
     "iopub.status.busy": "2023-05-01T14:41:58.502948Z",
     "iopub.status.idle": "2023-05-01T14:41:58.517278Z",
     "shell.execute_reply": "2023-05-01T14:41:58.516093Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.503492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def torch_tensor_to_plt(img):\n",
    "    img = img.detach().numpy()[0]\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.519588Z",
     "iopub.status.busy": "2023-05-01T14:41:58.518947Z",
     "iopub.status.idle": "2023-05-01T14:41:58.531757Z",
     "shell.execute_reply": "2023-05-01T14:41:58.530776Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.519544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([transforms.ToTensor(),\n",
    "                                  torchvision.transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.53345Z",
     "iopub.status.busy": "2023-05-01T14:41:58.533111Z",
     "iopub.status.idle": "2023-05-01T14:41:58.547977Z",
     "shell.execute_reply": "2023-05-01T14:41:58.54669Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.533416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageToTextDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transformer = transform\n",
    "        self.file = []\n",
    "        \n",
    "        file_list = glob.glob(join(self.path, '*'))\n",
    "        self.file = [file for file in file_list if (file.endswith(\".png\") or file.endswith(\".jpg\"))]\n",
    "        \n",
    "        for ban_file in BAN_DATA:\n",
    "            if ban_file in self.file:\n",
    "                self.file.remove(ban_file)\n",
    "        \n",
    "        self.num = len(self.file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "    \n",
    "    def transform(self, image):\n",
    "        if self.transformer!=None:\n",
    "            return self.transformer(image)\n",
    "        else :\n",
    "            return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.file[idx]\n",
    "        \n",
    "        Y = []\n",
    "        for char in list(filename.split(\"/\")[-1].split(\".\")[0]):\n",
    "            if(char == \"_\"):\n",
    "                break\n",
    "            Y.append(reversed_token_dictionary[char])\n",
    "            \n",
    "        if len(Y) < MAX_LEN:\n",
    "            Y += [reversed_token_dictionary[\"<pad>\"]]*(MAX_LEN-len(Y))\n",
    "        \n",
    "        img = cv2.imread(self.file[idx])\n",
    "        try:\n",
    "            sketch_image = cv2.cvtColor(img[:,:256,:], cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            print(self.file[idx])\n",
    "        X = self.transform(sketch_image)\n",
    "        \n",
    "        Y_tensor_list = []\n",
    "        for y_ind in Y:\n",
    "            y_tensor = torch.zeros(CHAR_NUM)\n",
    "            y_tensor[y_ind] = 1\n",
    "            Y_tensor_list.append(y_tensor.unsqueeze(0))\n",
    "\n",
    "        return X, torch.tensor(Y), torch.tensor(Y) #torch.cat(Y_tensor_list).transpose(-1, -2), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:58.550559Z",
     "iopub.status.busy": "2023-05-01T14:41:58.549731Z",
     "iopub.status.idle": "2023-05-01T14:41:59.485812Z",
     "shell.execute_reply": "2023-05-01T14:41:59.484825Z",
     "shell.execute_reply.started": "2023-05-01T14:41:58.55052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for dataset_path in DATASET_PATH:\n",
    "    dataset_list.append(ImageToTextDataset(dataset_path, transform=transformer))\n",
    "dataset = torch.utils.data.ConcatDataset(dataset_list)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset)-len(dataset)//10, len(dataset)//10])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Data ratio : {0}:{1}\".format(len(dataset)-len(dataset)//10, len(dataset)//10))\n",
    "print(\"Train data size : {0}\".format(len(train_dataset)))\n",
    "print(\"Test data size: {0}\".format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:59.487835Z",
     "iopub.status.busy": "2023-05-01T14:41:59.487097Z",
     "iopub.status.idle": "2023-05-01T14:41:59.613172Z",
     "shell.execute_reply": "2023-05-01T14:41:59.611676Z",
     "shell.execute_reply.started": "2023-05-01T14:41:59.487797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_val, _, target = dataset[0]\n",
    "print(x_val.shape)\n",
    "fig = plt.figure(figsize=(2, 2))\n",
    "plt.imshow(torch_tensor_to_plt(x_val.unsqueeze(0)), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(', '.join(map(str, target.tolist())))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - LACC (LAbel Combination Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:59.620886Z",
     "iopub.status.busy": "2023-05-01T14:41:59.619895Z",
     "iopub.status.idle": "2023-05-01T14:41:59.634654Z",
     "shell.execute_reply": "2023-05-01T14:41:59.633214Z",
     "shell.execute_reply.started": "2023-05-01T14:41:59.62082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LACC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torchvision.models.efficientnet_v2_m().features\n",
    "        self.converter = nn.parameter.Parameter(torch.ones(64, CHAR_NUM))        \n",
    "\n",
    "        self.silu = nn.SiLU()\n",
    "        self.linear1 = nn.Linear(1280, 512)\n",
    "        self.linear2 = nn.Linear(512, 64)\n",
    "        self.linear3 = nn.Linear(64, MAX_LEN)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.encoder(x)\n",
    "        #print(feature.shape)\n",
    "        feature = torch.flatten(feature, start_dim=2)\n",
    "        #print(feature.shape)\n",
    "        feature = torch.matmul(feature, self.converter)\n",
    "        \n",
    "        y = feature.transpose(-1, -2)\n",
    "        y = self.linear1(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.linear3(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:41:59.637443Z",
     "iopub.status.busy": "2023-05-01T14:41:59.636634Z",
     "iopub.status.idle": "2023-05-01T14:42:00.796358Z",
     "shell.execute_reply": "2023-05-01T14:42:00.795293Z",
     "shell.execute_reply.started": "2023-05-01T14:41:59.637392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = LACC().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:42:00.798864Z",
     "iopub.status.busy": "2023-05-01T14:42:00.798092Z",
     "iopub.status.idle": "2023-05-01T14:42:00.810412Z",
     "shell.execute_reply": "2023-05-01T14:42:00.809148Z",
     "shell.execute_reply.started": "2023-05-01T14:42:00.798815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = Lion(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:42:00.8147Z",
     "iopub.status.busy": "2023-05-01T14:42:00.813216Z",
     "iopub.status.idle": "2023-05-01T14:42:00.822307Z",
     "shell.execute_reply": "2023-05-01T14:42:00.821069Z",
     "shell.execute_reply.started": "2023-05-01T14:42:00.814651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(predict, y):\n",
    "    return criterion(predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:42:00.824745Z",
     "iopub.status.busy": "2023-05-01T14:42:00.824384Z",
     "iopub.status.idle": "2023-05-01T14:42:00.836263Z",
     "shell.execute_reply": "2023-05-01T14:42:00.835311Z",
     "shell.execute_reply.started": "2023-05-01T14:42:00.824711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getSimilar(list1, list2):\n",
    "    correct = 0\n",
    "    for item1, item2 in zip(list1, list2):\n",
    "        if item1==item2:\n",
    "            correct += 1\n",
    "    return correct    \n",
    "\n",
    "def getCorrect(list1, list2):\n",
    "    if ''.join(map(str,list1))==''.join(map(str,list2)):\n",
    "        return 1\n",
    "    else :\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:42:00.838884Z",
     "iopub.status.busy": "2023-05-01T14:42:00.837717Z",
     "iopub.status.idle": "2023-05-01T14:42:00.853792Z",
     "shell.execute_reply": "2023-05-01T14:42:00.852635Z",
     "shell.execute_reply.started": "2023-05-01T14:42:00.838833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evalSample(model, x, target, batch=0):\n",
    "    def replaceSpeicalToken(text):\n",
    "        text = text.replace('<pad>','□')\n",
    "        text = text.replace('<unk>','?')\n",
    "        return text\n",
    "    \n",
    "    x, target = x.to(device), target.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predict = model(x[batch].unsqueeze(0))\n",
    "    predict = F.log_softmax(predict, dim=-2)\n",
    "    predict = torch.argmax(predict, dim=-2)\n",
    "    \n",
    "    predict_text = \"\"\n",
    "    for token in predict[0].to(cpu_device).tolist():\n",
    "    \n",
    "        predict_text += str(token_dictionary[token])\n",
    "        \n",
    "    target_text = \"\"\n",
    "    for token in target[0].to(cpu_device).tolist():\n",
    "        target_text += str(token_dictionary[token])\n",
    "        \n",
    "    predict_text = replaceSpeicalToken(predict_text)\n",
    "    target_text = replaceSpeicalToken(target_text)\n",
    "        \n",
    "        \n",
    "        \n",
    "    fig = plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(torch_tensor_to_plt(x.to(cpu_device)[batch].unsqueeze(0)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Answer of AI : {predict_text} [Real Answer : {target_text}]\")\n",
    "    plt.show()\n",
    "    \n",
    "    return predict_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:43:02.846691Z",
     "iopub.status.busy": "2023-05-01T14:43:02.846234Z",
     "iopub.status.idle": "2023-05-01T14:43:02.860582Z",
     "shell.execute_reply": "2023-05-01T14:43:02.859104Z",
     "shell.execute_reply.started": "2023-05-01T14:43:02.846649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, train_dataloader, test_dataloader, epoch=None):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    accurate = 0.0\n",
    "    hard_accurate = 0.0\n",
    "    i = 1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    for x, y, label_target in train_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        predict = model(x)\n",
    "        predict = F.log_softmax(predict, dim=-2)\n",
    "        predict_text = torch.argmax(predict, dim=-2)\n",
    "        \n",
    "        loss = calculate_loss(predict, y)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        i += 1\n",
    "        if(i%1000 == 0):\n",
    "            print(f\"i = {i}, time : {time.time() - start_time}, train loss = {train_loss/i}\")\n",
    "    train_loss /= len(train_dataloader) \n",
    "    \n",
    "    # Testing\n",
    "    model.eval()\n",
    "    \n",
    "    for x, y, target in test_dataloader:\n",
    "        x, y, target = x.to(device), y.to(device), target.to(device)\n",
    "        \n",
    "        predict = model(x)\n",
    "        predict = F.log_softmax(predict, dim=-2)\n",
    "        \n",
    "        loss = calculate_loss(predict, y)\n",
    "        \n",
    "        predict = torch.argmax(predict, dim=-2)\n",
    "        \n",
    "        for predict_item, y_item in zip(predict, target):\n",
    "            accurate += getSimilar(predict_item, y_item)/(MAX_LEN*BATCH_SIZE)\n",
    "            hard_accurate += getCorrect(predict_item, y_item)/(BATCH_SIZE)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        \n",
    "    test_loss /= len(test_dataloader)    \n",
    "    accurate /= len(test_dataloader)\n",
    "    hard_accurate /= len(test_dataloader)\n",
    "    \n",
    "    if epoch != None:\n",
    "        print(f\"[Epoch {epoch}] Train Loss : {train_loss} & Test Loss : {test_loss} & Accurate : {accurate*100}% & Hard-Accurate : {hard_accurate*100}%\")\n",
    "        \n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:43:03.093852Z",
     "iopub.status.busy": "2023-05-01T14:43:03.093405Z",
     "iopub.status.idle": "2023-05-01T14:43:03.100309Z",
     "shell.execute_reply": "2023-05-01T14:43:03.098717Z",
     "shell.execute_reply.started": "2023-05-01T14:43:03.093809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if USE_CHECKPOINT:\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:43:03.413855Z",
     "iopub.status.busy": "2023-05-01T14:43:03.412904Z",
     "iopub.status.idle": "2023-05-01T14:43:41.446551Z",
     "shell.execute_reply": "2023-05-01T14:43:41.44499Z",
     "shell.execute_reply.started": "2023-05-01T14:43:03.413808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(START_EPOCH, START_EPOCH+EPOCHS):\n",
    "    train_loss, test_loss = train_one_epoch(model, optimizer, train_dataloader, test_dataloader, epoch=epoch)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-01T14:42:48.851235Z",
     "iopub.status.idle": "2023-05-01T14:42:48.851647Z",
     "shell.execute_reply": "2023-05-01T14:42:48.851448Z",
     "shell.execute_reply.started": "2023-05-01T14:42:48.851429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = np.array(list(range(START_EPOCH, START_EPOCH+EPOCHS)))\n",
    "plt.plot(x, np.array(train_loss_list),label='train')\n",
    "plt.plot(x, np.array(test_loss_list),label='test')\n",
    "plt.xlim([1, EPOCHS])\n",
    "plt.title(f\"Loss of IRT\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-01T14:42:48.853381Z",
     "iopub.status.idle": "2023-05-01T14:42:48.853792Z",
     "shell.execute_reply": "2023-05-01T14:42:48.853601Z",
     "shell.execute_reply.started": "2023-05-01T14:42:48.853582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for ind, (x, _, y) in enumerate(test_dataloader):\n",
    "    if ind > 10:\n",
    "        break\n",
    "    old_time = time.time()\n",
    "    predict_text, target_text = evalSample(model, x, y)\n",
    "    print(f\"{time.time()-old_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-01T14:42:48.855299Z",
     "iopub.status.idle": "2023-05-01T14:42:48.85654Z",
     "shell.execute_reply": "2023-05-01T14:42:48.856328Z",
     "shell.execute_reply.started": "2023-05-01T14:42:48.856303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': START_EPOCH+EPOCHS-1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'Checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 38019,
     "sourceId": 306654,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 807505,
     "sourceId": 1383737,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1193002,
     "sourceId": 1994695,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1499294,
     "sourceId": 2477380,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1510322,
     "sourceId": 2494662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3013698,
     "sourceId": 5183554,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6121145,
     "sourceId": 9953033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6121656,
     "sourceId": 9953758,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 128628855,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 168840,
     "modelInstanceId": 146297,
     "sourceId": 171877,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 168840,
     "modelInstanceId": 146297,
     "sourceId": 171993,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30408,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
